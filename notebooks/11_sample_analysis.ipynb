{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fd154a",
   "metadata": {},
   "source": [
    "# Sample Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f30e0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "4 different seeds with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61279212",
   "metadata": {},
   "source": [
    "* Seed A: 0\n",
    "* Seed B: 42\n",
    "* Seed C: 123\n",
    "* Seed D: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e7b50",
   "metadata": {},
   "source": [
    "652 samples with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ab05f",
   "metadata": {},
   "source": [
    "* TP: 163\n",
    "* TN: 163\n",
    "* FP: 163\n",
    "* FN: 163"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0966839",
   "metadata": {},
   "source": [
    "### Samples df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d95f347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-13 21:42:18.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmaster_thesis.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/takosaga/Projects/master_thesis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "from master_thesis.config import PROCESSED_DATA_DIR, load_dataframe_from_pickle, save_dataframe_as_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae86d51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>error</th>\n",
       "      <th>cardiff_label</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>shap_cardiff</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India is one nasty, dirty, filthy, germsy, law...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.994301</td>\n",
       "      <td>country: -0.13081460789510924, India: -0.11535...</td>\n",
       "      <td>: -1.309963408857584e-07, India : -0.137895100...</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solo que seras bombardeas y destruidos como lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.957913</td>\n",
       "      <td>virus: -0.6396167235678197, a: 0.2742073874468...</td>\n",
       "      <td>: 3.37468518409878e-05, s: -0.0331062855402706...</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user You cannot argue with a retard jer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.994864</td>\n",
       "      <td>retard: -0.6605584465804439, beggar: -0.131083...</td>\n",
       "      <td>: 1.7441052477806807e-06, @: 0.014520991622703...</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I just pound that pussy an pull your hair....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>your: -0.5835825358540915, hair: -0.1533505593...</td>\n",
       "      <td>: 9.252107702195644e-08, Can : 0.0115244268963...</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you do not live in america nazi faggot but you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.985650</td>\n",
       "      <td>faggot: -0.8942567996759809, nazi: -0.06532018...</td>\n",
       "      <td>: 1.1423340765759349e-05, you : 0.001079929454...</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  error cardiff_label  \\\n",
       "0  India is one nasty, dirty, filthy, germsy, law...    NaN          HATE   \n",
       "1  solo que seras bombardeas y destruidos como lo...    NaN          HATE   \n",
       "2  @user @user You cannot argue with a retard jer...    NaN          HATE   \n",
       "3  Can I just pound that pussy an pull your hair....    NaN          HATE   \n",
       "4  you do not live in america nazi faggot but you...    NaN          HATE   \n",
       "\n",
       "   cardiff_score                                       lime_cardiff  \\\n",
       "0       0.994301  country: -0.13081460789510924, India: -0.11535...   \n",
       "1       0.957913  virus: -0.6396167235678197, a: 0.2742073874468...   \n",
       "2       0.994864  retard: -0.6605584465804439, beggar: -0.131083...   \n",
       "3       0.977588  your: -0.5835825358540915, hair: -0.1533505593...   \n",
       "4       0.985650  faggot: -0.8942567996759809, nazi: -0.06532018...   \n",
       "\n",
       "                                        shap_cardiff  seed  \n",
       "0  : -1.309963408857584e-07, India : -0.137895100...  3279  \n",
       "1  : 3.37468518409878e-05, s: -0.0331062855402706...  3279  \n",
       "2  : 1.7441052477806807e-06, @: 0.014520991622703...  3279  \n",
       "3  : 9.252107702195644e-08, Can : 0.0115244268963...  3279  \n",
       "4  : 1.1423340765759349e-05, you : 0.001079929454...  3279  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = load_dataframe_from_pickle(\n",
    "    PROCESSED_DATA_DIR / \"experiment_rerun.pkl\"\n",
    ")\n",
    "\n",
    "working_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed06d02",
   "metadata": {},
   "source": [
    "df_shaps_only = load_dataframe_from_pickle(\n",
    "    PROCESSED_DATA_DIR / \"samples_SHAP_seed_correction.pkl\"\n",
    ")\n",
    "\n",
    "df_shaps_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82cbc3",
   "metadata": {},
   "source": [
    "working_df['shap_cardiff_seed_double_check'] = df_shaps_only['shap_cardiff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06c9e7",
   "metadata": {},
   "source": [
    "d = dtale.show(df_shaps_only)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182f938a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a5a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['cardiff_hatespeech'] = working_df['cardiff_label'].apply(lambda x: 1 if x == 'HATE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa64ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df.drop(columns=['cardiff_label'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb16afd",
   "metadata": {},
   "source": [
    "### Full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d664691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_new</th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>label_hatespeech_binary_offensive_not_included</th>\n",
       "      <th>label_hatespeech_binary_offensive_included</th>\n",
       "      <th>label_normal_offensive_hatespeech</th>\n",
       "      <th>platform</th>\n",
       "      <th>original_dataset_title</th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_label</th>\n",
       "      <th>original_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179055004553900032</td>\n",
       "      <td>normal</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179063826874032128</td>\n",
       "      <td>normal</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>{race}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1178793830532956161</td>\n",
       "      <td>normal</td>\n",
       "      <td>[African]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>{race}</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech/offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179088797964763136</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[Asian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>{race, gender}</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech/offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179085312976445440</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[Caucasian, Women]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_new                                               text extracted_target  \\\n",
       "0       1  i dont think im getting my baby them white 9 h...           {none}   \n",
       "1       2  we cannot continue calling ourselves feminists...           {none}   \n",
       "2       3                      nawt yall niggers ignoring me           {race}   \n",
       "3       4  <user> i am bit confused coz chinese ppl can n...           {race}   \n",
       "4       5  this bitch in whataburger eating a burger with...   {race, gender}   \n",
       "\n",
       "  label_hatespeech_binary_offensive_not_included  \\\n",
       "0                                 not_hatespeech   \n",
       "1                                 not_hatespeech   \n",
       "2                                 not_hatespeech   \n",
       "3                                     hatespeech   \n",
       "4                                     hatespeech   \n",
       "\n",
       "  label_hatespeech_binary_offensive_included  \\\n",
       "0                                     normal   \n",
       "1                                     normal   \n",
       "2                                     normal   \n",
       "3                       hatespeech/offensive   \n",
       "4                       hatespeech/offensive   \n",
       "\n",
       "  label_normal_offensive_hatespeech platform original_dataset_title  \\\n",
       "0                            normal  twitter             HateXplain   \n",
       "1                            normal  twitter             HateXplain   \n",
       "2                            normal  twitter             HateXplain   \n",
       "3                        hatespeech  twitter             HateXplain   \n",
       "4                        hatespeech  twitter             HateXplain   \n",
       "\n",
       "           original_id original_label     original_target  \n",
       "0  1179055004553900032         normal              [None]  \n",
       "1  1179063826874032128         normal              [None]  \n",
       "2  1178793830532956161         normal           [African]  \n",
       "3  1179088797964763136     hatespeech             [Asian]  \n",
       "4  1179085312976445440     hatespeech  [Caucasian, Women]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hatespeech_df = load_dataframe_from_pickle(\n",
    "    PROCESSED_DATA_DIR / \"annotated_and_targeted_hatespeech.pkl\"\n",
    ")\n",
    "\n",
    "full_hatespeech_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69c2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['id_new', 'text', 'extracted_target','label_hatespeech_binary_offensive_included','platform']\n",
    "adjusted_hatespeech_df = full_hatespeech_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54873f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70712/2421778535.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_70712/2421778535.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adjusted_hatespeech_df['is_hatespeech'] = adjusted_hatespeech_df['label_hatespeech_binary_offensive_included'].apply(lambda x: 1 if x == 'hatespeech/offensive' else 0)\n",
    "adjusted_hatespeech_df['id'] = adjusted_hatespeech_df['id_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e4962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70712/3016290075.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adjusted_hatespeech_df.drop(columns=['label_hatespeech_binary_offensive_included','id_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40540ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(working_df, adjusted_hatespeech_df, on='text', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949fe4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "d = dtale.show(full_df)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82da379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.drop('error', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bbb3113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'cardiff_score', 'lime_cardiff', 'shap_cardiff', 'seed',\n",
       "       'cardiff_hatespeech', 'extracted_target', 'platform', 'is_hatespeech',\n",
       "       'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18053ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>shap_cardiff</th>\n",
       "      <th>seed</th>\n",
       "      <th>cardiff_hatespeech</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_hatespeech</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India is one nasty, dirty, filthy, germsy, law...</td>\n",
       "      <td>0.994301</td>\n",
       "      <td>country: -0.13081460789510924, India: -0.11535...</td>\n",
       "      <td>: -1.309963408857584e-07, India : -0.137895100...</td>\n",
       "      <td>3279</td>\n",
       "      <td>1</td>\n",
       "      <td>{nationality}</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "      <td>53513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solo que seras bombardeas y destruidos como lo...</td>\n",
       "      <td>0.957913</td>\n",
       "      <td>virus: -0.6396167235678197, a: 0.2742073874468...</td>\n",
       "      <td>: 3.37468518409878e-05, s: -0.0331062855402706...</td>\n",
       "      <td>3279</td>\n",
       "      <td>1</td>\n",
       "      <td>{religion}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user You cannot argue with a retard jer...</td>\n",
       "      <td>0.994864</td>\n",
       "      <td>retard: -0.6605584465804439, beggar: -0.131083...</td>\n",
       "      <td>: 1.7441052477806807e-06, @: 0.014520991622703...</td>\n",
       "      <td>3279</td>\n",
       "      <td>1</td>\n",
       "      <td>{nationality, disability}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>64112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I just pound that pussy an pull your hair....</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>your: -0.5835825358540915, hair: -0.1533505593...</td>\n",
       "      <td>: 9.252107702195644e-08, Can : 0.0115244268963...</td>\n",
       "      <td>3279</td>\n",
       "      <td>1</td>\n",
       "      <td>{gender}</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>22034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you do not live in america nazi faggot but you...</td>\n",
       "      <td>0.985650</td>\n",
       "      <td>faggot: -0.8942567996759809, nazi: -0.06532018...</td>\n",
       "      <td>: 1.1423340765759349e-05, you : 0.001079929454...</td>\n",
       "      <td>3279</td>\n",
       "      <td>1</td>\n",
       "      <td>{sexuality}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>18143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cardiff_score  \\\n",
       "0  India is one nasty, dirty, filthy, germsy, law...       0.994301   \n",
       "1  solo que seras bombardeas y destruidos como lo...       0.957913   \n",
       "2  @user @user You cannot argue with a retard jer...       0.994864   \n",
       "3  Can I just pound that pussy an pull your hair....       0.977588   \n",
       "4  you do not live in america nazi faggot but you...       0.985650   \n",
       "\n",
       "                                        lime_cardiff  \\\n",
       "0  country: -0.13081460789510924, India: -0.11535...   \n",
       "1  virus: -0.6396167235678197, a: 0.2742073874468...   \n",
       "2  retard: -0.6605584465804439, beggar: -0.131083...   \n",
       "3  your: -0.5835825358540915, hair: -0.1533505593...   \n",
       "4  faggot: -0.8942567996759809, nazi: -0.06532018...   \n",
       "\n",
       "                                        shap_cardiff  seed  \\\n",
       "0  : -1.309963408857584e-07, India : -0.137895100...  3279   \n",
       "1  : 3.37468518409878e-05, s: -0.0331062855402706...  3279   \n",
       "2  : 1.7441052477806807e-06, @: 0.014520991622703...  3279   \n",
       "3  : 9.252107702195644e-08, Can : 0.0115244268963...  3279   \n",
       "4  : 1.1423340765759349e-05, you : 0.001079929454...  3279   \n",
       "\n",
       "   cardiff_hatespeech           extracted_target platform is_hatespeech     id  \n",
       "0                   1              {nationality}  youtube             1  53513  \n",
       "1                   1                 {religion}      gab             1   8335  \n",
       "2                   1  {nationality, disability}  twitter             1  64112  \n",
       "3                   1                   {gender}   reddit             1  22034  \n",
       "4                   1                {sexuality}      gab             1  18143  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b6e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>shap_cardiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country: -0.13081460789510924, India: -0.11535...</td>\n",
       "      <td>: -1.309963408857584e-07, India : -0.137895100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virus: -0.6396167235678197, a: 0.2742073874468...</td>\n",
       "      <td>: 3.37468518409878e-05, s: -0.0331062855402706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retard: -0.6605584465804439, beggar: -0.131083...</td>\n",
       "      <td>: 1.7441052477806807e-06, @: 0.014520991622703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your: -0.5835825358540915, hair: -0.1533505593...</td>\n",
       "      <td>: 9.252107702195644e-08, Can : 0.0115244268963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faggot: -0.8942567996759809, nazi: -0.06532018...</td>\n",
       "      <td>: 1.1423340765759349e-05, you : 0.001079929454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>kike: -0.14370667110505084, jesus: 0.132638644...</td>\n",
       "      <td>: 4.0978193283081055e-08, um : 0.0233726911246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>pathetic: -0.23700872838377945, a: 0.215914702...</td>\n",
       "      <td>: 4.0357311566670734e-07, Mom: 0.0108912767221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>nigger: -0.52147452135587, say: 0.421584531242...</td>\n",
       "      <td>: -2.2202730178833008e-06, Black : 0.008567720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>retard: -0.6576435617962614, I: 0.314014873883...</td>\n",
       "      <td>: -1.862645149230957e-08, pretty : 0.104445570...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>the: 0.4545588655018975, twat: -0.363572963766...</td>\n",
       "      <td>@: 0.0006309300661087036, user : 0.00325017422...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           lime_cardiff  \\\n",
       "0     country: -0.13081460789510924, India: -0.11535...   \n",
       "1     virus: -0.6396167235678197, a: 0.2742073874468...   \n",
       "2     retard: -0.6605584465804439, beggar: -0.131083...   \n",
       "3     your: -0.5835825358540915, hair: -0.1533505593...   \n",
       "4     faggot: -0.8942567996759809, nazi: -0.06532018...   \n",
       "...                                                 ...   \n",
       "2603  kike: -0.14370667110505084, jesus: 0.132638644...   \n",
       "2604  pathetic: -0.23700872838377945, a: 0.215914702...   \n",
       "2605  nigger: -0.52147452135587, say: 0.421584531242...   \n",
       "2606  retard: -0.6576435617962614, I: 0.314014873883...   \n",
       "2607  the: 0.4545588655018975, twat: -0.363572963766...   \n",
       "\n",
       "                                           shap_cardiff  \n",
       "0     : -1.309963408857584e-07, India : -0.137895100...  \n",
       "1     : 3.37468518409878e-05, s: -0.0331062855402706...  \n",
       "2     : 1.7441052477806807e-06, @: 0.014520991622703...  \n",
       "3     : 9.252107702195644e-08, Can : 0.0115244268963...  \n",
       "4     : 1.1423340765759349e-05, you : 0.001079929454...  \n",
       "...                                                 ...  \n",
       "2603  : 4.0978193283081055e-08, um : 0.0233726911246...  \n",
       "2604  : 4.0357311566670734e-07, Mom: 0.0108912767221...  \n",
       "2605  : -2.2202730178833008e-06, Black : 0.008567720...  \n",
       "2606  : -1.862645149230957e-08, pretty : 0.104445570...  \n",
       "2607  @: 0.0006309300661087036, user : 0.00325017422...  \n",
       "\n",
       "[2608 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[['lime_cardiff','shap_cardiff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b2fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "d = dtale.show(full_df[['lime_cardiff','shap_cardiff']])\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34c0fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_df['lime_cardiff'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28df52",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1876589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_and_rank_features(feature_string):\n",
    "    \"\"\"\n",
    "    Parses a string of feature contributions, ranks them by absolute weight,\n",
    "    and returns the top 5.\n",
    "\n",
    "    Args:\n",
    "        feature_string (str): A string in the format like \"feat1: val1, feat2: val2, ...\"\n",
    "                              or \": val1, feat2: val2, ...\" or \"val1, feat2: val2, ...\".\n",
    "                              It can also be None, NaN, or an empty string.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of up to 5 tuples, where each tuple is (feature_name, original_weight).\n",
    "              The list is sorted by the absolute value of the weights in descending order.\n",
    "              Returns an empty list if the input is invalid or no features are parsed.\n",
    "    \"\"\"\n",
    "    if not isinstance(feature_string, str) or not feature_string.strip():\n",
    "        # Handles None, NaN, empty string, or string with only whitespace\n",
    "        return []\n",
    "\n",
    "    # Split the main string by commas to get individual feature parts\n",
    "    raw_items = feature_string.split(',')\n",
    "    \n",
    "    feature_contributions = []\n",
    "    for raw_item in raw_items:\n",
    "        item = raw_item.strip()  # Remove leading/trailing whitespace from the part\n",
    "        if not item:\n",
    "            continue  # Skip if the part is empty after stripping\n",
    "\n",
    "        # We use rpartition(':') to split the item by the *last* colon.\n",
    "        # This is robust in case a feature name itself contains a colon.\n",
    "        # - If \"name:value\", parts are ('name', ':', 'value')\n",
    "        # - If \":value\", parts are ('', ':', 'value')\n",
    "        # - If \"value\" (no colon), parts are ('value', '', '')\n",
    "        name_part, separator, value_part = item.rpartition(':')\n",
    "        \n",
    "        feature_name = \"\"\n",
    "        weight_str = \"\"\n",
    "\n",
    "        if separator == ':':\n",
    "            # This is the common case, e.g., \"feature_name: 0.5\" or \": 0.5\"\n",
    "            feature_name = name_part.strip()\n",
    "            weight_str = value_part.strip()\n",
    "        else:\n",
    "            # No colon was found in this item. Assume the entire item is a weight\n",
    "            # for an unnamed feature. e.g. \"0.5\" becomes feature=\"\", weight=\"0.5\"\n",
    "            feature_name = \"\"  # Default to an empty string for the feature name\n",
    "            weight_str = name_part.strip() # The whole item (name_part here) is the weight string\n",
    "\n",
    "        if not weight_str:\n",
    "            # This occurs if the item was like \"feature_name:\" (empty after colon)\n",
    "            # or if after parsing, weight_str ended up empty.\n",
    "            # print(f\"Warning: No weight value found for item '{item}'. Skipping.\") # Optional: for debugging\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            weight = float(weight_str)\n",
    "            feature_contributions.append({\n",
    "                'feature': feature_name, \n",
    "                'weight': weight, \n",
    "                'abs_weight': abs(weight)\n",
    "            })\n",
    "        except ValueError:\n",
    "            # This occurs if the weight_str cannot be converted to a float.\n",
    "            # print(f\"Warning: Could not parse weight from '{weight_str}' in item '{item}'. Skipping.\") # Optional: for debugging\n",
    "            continue\n",
    "            \n",
    "    # Sort the collected features by their absolute weight in descending order\n",
    "    sorted_features = sorted(feature_contributions, key=lambda x: x['abs_weight'], reverse=True)\n",
    "    \n",
    "    # Get the top 5 (or fewer if not enough features were parsed)\n",
    "    top_5 = [(f['feature'], f['weight']) for f in sorted_features[:5]]\n",
    "    \n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f456e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'lime_cardiff' column\n",
    "full_df['lime_top5'] = full_df['lime_cardiff'].apply(parse_and_rank_features)\n",
    "\n",
    "# Apply the function to the 'shap_cardiff' column\n",
    "full_df['shap_top5'] = full_df['shap_cardiff'].apply(parse_and_rank_features)\n",
    "\n",
    "# Sanity check with shap_cardiff_seed_double_check\n",
    "# full_df['shap_top5'] = full_df['shap_cardiff_seed_double_check'].apply(parse_and_rank_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5769a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = dtale.show(full_df[['lime_top5','shap_top5']])\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80462376",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(full_df)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "522f8c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 21:48:12,940 - INFO     - Executing shutdown...\n",
      "2025-05-13 21:48:12,941 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n"
     ]
    }
   ],
   "source": [
    "d.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d9f714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_df['lime_top5'][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f991a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_names(top_features_list):\n",
    "    \"\"\"\n",
    "    Extracts only the feature names from a list of (feature_name, weight) tuples.\n",
    "    The order of feature names is preserved.\n",
    "\n",
    "    Args:\n",
    "        top_features_list (list): A list of tuples, where each tuple is expected\n",
    "                                  to be (feature_name, weight). This is typically\n",
    "                                  the output from the parse_and_rank_features function.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings (feature names). Returns an empty list if the\n",
    "              input is not a list or is empty.\n",
    "    \"\"\"\n",
    "    if not isinstance(top_features_list, list):\n",
    "        # Handles cases where the input might not be a list (e.g., if an error occurred upstream)\n",
    "        return []\n",
    "    \n",
    "    # Extracts the first element (feature name) from each tuple in the list\n",
    "    # Ensures that it only processes actual tuples with at least one element\n",
    "    feature_names = [\n",
    "        feature_tuple[0] \n",
    "        for feature_tuple in top_features_list \n",
    "        if isinstance(feature_tuple, tuple) and len(feature_tuple) > 0\n",
    "    ]\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ca7adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new function to the 'lime_top5' column\n",
    "full_df['lime_top5_names'] = full_df['lime_top5'].apply(extract_feature_names)\n",
    "\n",
    "# Apply the new function to the 'shap_top5' column\n",
    "full_df['shap_top5_names'] = full_df['shap_top5'].apply(extract_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c423e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(full_df[['id','lime_top5_names','shap_top5_names','seed']])\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f6161b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 21:48:20,473 - INFO     - Executing shutdown...\n",
      "2025-05-13 21:48:20,474 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n"
     ]
    }
   ],
   "source": [
    "d.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb18292",
   "metadata": {},
   "source": [
    "### Applying Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ee0c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_similarity(list1, list2):\n",
    "    \"\"\"\n",
    "    Calculates the Jaccard similarity between two lists of feature names.\n",
    "    \"\"\"\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 1.0 # Or 0.0, depending on how you want to treat two empty lists\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d9fc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rank_correlation(list1, list2, method='spearman'):\n",
    "    \"\"\"\n",
    "    Calculates Spearman's rank correlation or Kendall's Tau for two lists of feature names.\n",
    "    Features are ranked by their position in the list.\n",
    "    Features not present in one list but present in the other are handled by\n",
    "    assigning them a rank lower than any item in the list.\n",
    "    \n",
    "    Args:\n",
    "        list1 (list): First list of feature names (ordered).\n",
    "        list2 (list): Second list of feature names (ordered).\n",
    "        method (str): 'spearman' or 'kendall'.\n",
    "\n",
    "    Returns:\n",
    "        float: The correlation coefficient. Returns NaN if lists are too short or have no overlap.\n",
    "    \"\"\"\n",
    "    all_features = list(set(list1) | set(list2))\n",
    "    if not all_features:\n",
    "        return 1.0 # Or NaN, if both lists are empty\n",
    "\n",
    "    # Create ranks for each list.\n",
    "    # Features present get their 0-indexed position as rank.\n",
    "    # Features not present get a rank equal to the length of the list (lower importance).\n",
    "    ranks1 = {feature: i for i, feature in enumerate(list1)}\n",
    "    ranks2 = {feature: i for i, feature in enumerate(list2)}\n",
    "\n",
    "    vec1 = [ranks1.get(f, len(list1)) for f in all_features]\n",
    "    vec2 = [ranks2.get(f, len(list2)) for f in all_features]\n",
    "\n",
    "    if len(vec1) < 2 or len(vec2) < 2 : # Correlation is not well-defined for single elements\n",
    "        return None # Or handle as per your needs, e.g. 0 or 1 if lists are identical but short\n",
    "\n",
    "    # Handle cases where all ranks are the same (no variance), scipy might return NaN or error\n",
    "    if len(set(vec1)) <= 1 or len(set(vec2)) <= 1:\n",
    "         if vec1 == vec2: # If they are identical constant lists\n",
    "             return 1.0\n",
    "         else: # Different constant lists or one constant, one not\n",
    "             return 0.0 # Or None, as correlation is tricky here\n",
    "\n",
    "    if method == 'spearman':\n",
    "        corr, _ = spearmanr(vec1, vec2)\n",
    "    elif method == 'kendall':\n",
    "        corr, _ = kendalltau(vec1, vec2)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'spearman' or 'kendall'\")\n",
    "    \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede6ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] # To store the comparison results\n",
    "\n",
    "# Group by 'id'\n",
    "grouped_by_id = full_df.groupby('id')\n",
    "\n",
    "for id_val, group in grouped_by_id:\n",
    "    if len(group) < 2: # Need at least two different seeds for comparison\n",
    "        continue\n",
    "\n",
    "    # Convert rows to a list of tuples (seed, feature_list) for easier iteration\n",
    "    # Focusing on LIME for this example:\n",
    "    seed_feature_lists_lime = []\n",
    "    for _, row in group.iterrows():\n",
    "        seed_feature_lists_lime.append((row['seed'], row['lime_top5_names']))\n",
    "    \n",
    "    seed_feature_lists_shap = []\n",
    "    for _, row in group.iterrows():\n",
    "        seed_feature_lists_shap.append((row['seed'], row['shap_top5_names']))\n",
    "\n",
    "\n",
    "    # Pairwise comparison for LIME lists within the current 'id' group\n",
    "    for i in range(len(seed_feature_lists_lime)):\n",
    "        for j in range(i + 1, len(seed_feature_lists_lime)):\n",
    "            seed1, list1 = seed_feature_lists_lime[i]\n",
    "            seed2, list2 = seed_feature_lists_lime[j]\n",
    "\n",
    "            # Ensure lists are actually lists (they should be from .apply(extract_feature_names))\n",
    "            if not isinstance(list1, list) or not isinstance(list2, list):\n",
    "                print(f\"Warning: Skipping comparison for id {id_val}, seeds {seed1}-{seed2} due to non-list feature set.\")\n",
    "                continue\n",
    "            \n",
    "            jaccard_sim = calculate_jaccard_similarity(list1, list2)\n",
    "            spearman_corr = calculate_rank_correlation(list1, list2, method='spearman')\n",
    "            kendall_tau_val = calculate_rank_correlation(list1, list2, method='kendall')\n",
    "\n",
    "            results.append({\n",
    "                'id': id_val,\n",
    "                'seed1': seed1,\n",
    "                'seed2': seed2,\n",
    "                'comparison_type': 'lime_top5_names', # Specify which list type was compared\n",
    "                'jaccard_similarity': jaccard_sim,\n",
    "                'spearman_correlation': spearman_corr,\n",
    "                'kendall_tau': kendall_tau_val\n",
    "            })\n",
    "    \n",
    "    for i in range(len(seed_feature_lists_shap)):\n",
    "        for j in range(i + 1, len(seed_feature_lists_shap)):\n",
    "            seed1, list1_shap = seed_feature_lists_shap[i]\n",
    "            seed2, list2_shap = seed_feature_lists_shap[j]\n",
    "            \n",
    "            if not isinstance(list1_shap, list) or not isinstance(list2_shap, list):\n",
    "                continue # Skip if data is not as expected\n",
    "\n",
    "            jaccard_sim_shap = calculate_jaccard_similarity(list1_shap, list2_shap)\n",
    "            spearman_corr_shap = calculate_rank_correlation(list1_shap, list2_shap, method='spearman')\n",
    "            kendall_tau_shap = calculate_rank_correlation(list1_shap, list2_shap, method='kendall')\n",
    "\n",
    "            results.append({\n",
    "                'id': id_val,\n",
    "                'seed1': seed1,\n",
    "                'seed2': seed2,\n",
    "                'comparison_type': 'shap_top5_names',\n",
    "                'jaccard_similarity': jaccard_sim_shap,\n",
    "                'spearman_correlation': spearman_corr_shap,\n",
    "            'kendall_tau': kendall_tau_shap\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7c68b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seed1</th>\n",
       "      <th>seed2</th>\n",
       "      <th>comparison_type</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>spearman_correlation</th>\n",
       "      <th>kendall_tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3279</td>\n",
       "      <td>14593</td>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3279</td>\n",
       "      <td>83811</td>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3279</td>\n",
       "      <td>97197</td>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14593</td>\n",
       "      <td>83811</td>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>14593</td>\n",
       "      <td>97197</td>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  seed1  seed2  comparison_type  jaccard_similarity  \\\n",
       "0   7   3279  14593  lime_top5_names            0.666667   \n",
       "1   7   3279  83811  lime_top5_names            1.000000   \n",
       "2   7   3279  97197  lime_top5_names            1.000000   \n",
       "3   7  14593  83811  lime_top5_names            0.666667   \n",
       "4   7  14593  97197  lime_top5_names            0.666667   \n",
       "\n",
       "   spearman_correlation  kendall_tau  \n",
       "0              0.828571     0.733333  \n",
       "1              0.900000     0.800000  \n",
       "2              0.900000     0.800000  \n",
       "3              0.942857     0.866667  \n",
       "4              0.942857     0.866667  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce3dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dtale.show(results_df)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416d0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 21:49:23,359 - INFO     - Executing shutdown...\n",
      "2025-05-13 21:49:23,359 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n"
     ]
    }
   ],
   "source": [
    "d.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b66fd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparison_type</th>\n",
       "      <th>jaccard_similarity_mean</th>\n",
       "      <th>jaccard_similarity_std</th>\n",
       "      <th>jaccard_similarity_min</th>\n",
       "      <th>jaccard_similarity_max</th>\n",
       "      <th>spearman_correlation_mean</th>\n",
       "      <th>spearman_correlation_std</th>\n",
       "      <th>spearman_correlation_min</th>\n",
       "      <th>spearman_correlation_max</th>\n",
       "      <th>kendall_tau_mean</th>\n",
       "      <th>kendall_tau_std</th>\n",
       "      <th>kendall_tau_min</th>\n",
       "      <th>kendall_tau_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lime_top5_names</td>\n",
       "      <td>0.834925</td>\n",
       "      <td>0.193046</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850664</td>\n",
       "      <td>2.058764e-01</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.776246</td>\n",
       "      <td>2.350756e-01</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shap_top5_names</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.254138e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.254138e-17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comparison_type  jaccard_similarity_mean  jaccard_similarity_std  \\\n",
       "0  lime_top5_names                 0.834925                0.193046   \n",
       "1  shap_top5_names                 1.000000                0.000000   \n",
       "\n",
       "   jaccard_similarity_min  jaccard_similarity_max  spearman_correlation_mean  \\\n",
       "0                    0.25                     1.0                   0.850664   \n",
       "1                    1.00                     1.0                   1.000000   \n",
       "\n",
       "   spearman_correlation_std  spearman_correlation_min  \\\n",
       "0              2.058764e-01                      -0.6   \n",
       "1              3.254138e-17                       1.0   \n",
       "\n",
       "   spearman_correlation_max  kendall_tau_mean  kendall_tau_std  \\\n",
       "0                       1.0          0.776246     2.350756e-01   \n",
       "1                       1.0          1.000000     3.254138e-17   \n",
       "\n",
       "   kendall_tau_min  kendall_tau_max  \n",
       "0            -0.48              1.0  \n",
       "1             1.00              1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['jaccard_similarity', 'spearman_correlation', 'kendall_tau']\n",
    "\n",
    "# define the aggregation functions\n",
    "agg_funcs = ['mean', 'std', 'min', 'max']\n",
    "\n",
    "# perform the grouped aggregation\n",
    "summary = (\n",
    "    results_df\n",
    "    .groupby('comparison_type')[metrics]\n",
    "    .agg(agg_funcs)\n",
    ")\n",
    "\n",
    "# flatten the MultiIndex columns\n",
    "summary.columns = ['_'.join(col) for col in summary.columns]\n",
    "\n",
    "# (optional) reset index if you want 'comparison_type' back as a column\n",
    "summary = summary.reset_index()\n",
    "\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
