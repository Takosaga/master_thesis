{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6f623e",
   "metadata": {},
   "source": [
    "# Shap Seed Reruns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f206c",
   "metadata": {},
   "source": [
    "https://lime-ml.readthedocs.io/en/latest/lime.html\n",
    "\n",
    "random_state â€“ an integer or numpy.RandomState that will be used to generate random numbers. If None, the random state will be initialized using the internal numpy seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df10f9b",
   "metadata": {},
   "source": [
    "https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html\n",
    "\n",
    "seed: None or int\n",
    "seed for reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53942e",
   "metadata": {},
   "source": [
    "Initial runs had the following to reset seed\n",
    "```\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        # Optional: for determinism with CuDNN\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36520cf9",
   "metadata": {},
   "source": [
    "SHAP may not have had adjusted seed values, so will rerun with seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbd913",
   "metadata": {},
   "source": [
    "### Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f508a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install shap hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8e0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b6d2a0e05540b49cf4216ff29dd895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>error</th>\n",
       "      <th>cardiff_label</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>shap_cardiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>None</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>: -4.889443516731262e-08, n: 0.009972625062800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>None</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>: 1.1641532182693481e-10, and : 0.002760913455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a neutral sentence</td>\n",
       "      <td>None</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.999157</td>\n",
       "      <td>this : 0.0007638931274414062, is : 0.000668436...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text error cardiff_label  \\\n",
       "0                      nawt yall niggers ignoring me  None          HATE   \n",
       "1  and this is why i end up with nigger trainee d...  None          HATE   \n",
       "2                         this is a neutral sentence  None      NOT-HATE   \n",
       "\n",
       "   cardiff_score                                       shap_cardiff  \n",
       "0       0.935527  : -4.889443516731262e-08, n: 0.009972625062800...  \n",
       "1       0.993975  : 1.1641532182693481e-10, and : 0.002760913455...  \n",
       "2       0.999157  this : 0.0007638931274414062, is : 0.000668436...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity test\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import random\n",
    "import torch\n",
    "from typing import List, Union\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        # Optional: for determinism with CuDNN\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Constants\n",
    "CLASS_NAMES = ['NOT-HATE', 'HATE']\n",
    "BATCH_SIZE = 512  # Adjust based on your GPU memory\n",
    "\n",
    "# Load models and tokenizers once\n",
    "pipe_cardiff = pipeline(\"text-classification\", \n",
    "                       model=\"cardiffnlp/twitter-roberta-base-hate-latest\", \n",
    "                       device=0 if torch.cuda.is_available() else -1,\n",
    "                       batch_size=BATCH_SIZE)\n",
    "\n",
    "tokenizer_cardiff = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-hate-latest\")\n",
    "\n",
    "# Create dataset class for more efficient processing\n",
    "class HateSpeechDataset:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "\n",
    "# Unified prediction function for both models\n",
    "def batch_predict(texts: Union[List[str], np.ndarray], pipeline_fn):\n",
    "    \"\"\"Run predictions in batches for efficiency\"\"\"\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "        \n",
    "    dataset = HateSpeechDataset(texts)\n",
    "    \n",
    "    # Process in batches\n",
    "    all_outputs = []\n",
    "    for i in range(0, len(dataset), BATCH_SIZE):\n",
    "        batch_texts = [dataset[j] for j in range(i, min(i + BATCH_SIZE, len(dataset)))]\n",
    "        outputs = pipeline_fn(batch_texts, top_k=2)\n",
    "        all_outputs.extend(outputs)\n",
    "    \n",
    "    # Convert to numpy array with consistent order\n",
    "    return np.array([\n",
    "        [label['score'] for label in sorted(res, key=lambda x: x['label'])]\n",
    "        for res in all_outputs\n",
    "    ])\n",
    "\n",
    "\n",
    "# Model-specific prediction functions\n",
    "def predict_cardiff(texts):\n",
    "    return batch_predict(texts, pipe_cardiff)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "explainer_shap_cardiff = shap.Explainer(predict_cardiff,\n",
    "                                       seed=0,\n",
    "                                       masker=shap.maskers.Text(tokenizer_cardiff))\n",
    "\n",
    "# Helper function for SHAP explanations\n",
    "def get_shap_values(text, explainer, class_idx=1):\n",
    "    shap_vals = explainer([text])\n",
    "    return \", \".join([\n",
    "        f\"{feature}: {value}\"\n",
    "        for feature, value in zip(shap_vals[0].data, shap_vals[0].values[:, class_idx])\n",
    "        if abs(value) != 0\n",
    "    ])\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"nawt yall niggers ignoring me\",\n",
    "        \"and this is why i end up with nigger trainee doctors who can not speak properly lack basic knowledge of biology it truly scary if the public only knew\",\n",
    "        \"this is a neutral sentence\"\n",
    "    ]\n",
    "}\n",
    "annotated_and_targeted_hatespeech_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Process all texts in one batch for efficiency\n",
    "all_texts = annotated_and_targeted_hatespeech_df[\"text\"].tolist()\n",
    "\n",
    "# Get predictions in batch\n",
    "cardiff_preds = pipe_cardiff(all_texts) \n",
    "\n",
    "# Process results\n",
    "results = []\n",
    "for i, text in enumerate(all_texts):\n",
    "    try:\n",
    "        # Get predictions from the batch results\n",
    "        pred_cardiff = cardiff_preds[i]\n",
    "\n",
    "\n",
    "        # SHAP explanations\n",
    "        shap_exp_cardiff = get_shap_values(text, explainer_shap_cardiff)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"error\": None,\n",
    "            \"cardiff_label\": pred_cardiff[\"label\"],\n",
    "            \"cardiff_score\": pred_cardiff[\"score\"],\n",
    "            \"shap_cardiff\": shap_exp_cardiff\n",
    "        })\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"error\": f\"Caught an exception: {e}\",\n",
    "            \"cardiff_label\": None,\n",
    "            \"cardiff_score\": None,\n",
    "            \"shap_cardiff\": None\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Save to your Google Drive\n",
    "final_df.to_csv('/content/drive/MyDrive/hate_speech_analysis_results.csv', index=False)\n",
    "final_df.to_excel('/content/drive/MyDrive/hate_speech_analysis_results.xlsx', index=False)\n",
    "final_df.to_pickle('/content/drive/MyDrive/hate_speech_analysis_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c418118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully with 652 rows\n",
      "\n",
      "Preview of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_hatespeech</th>\n",
       "      <th>id</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>cardiff_hatespeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India is one nasty, dirty, filthy, germsy, law...</td>\n",
       "      <td>{nationality}</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "      <td>53513</td>\n",
       "      <td>0.994301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solo que seras bombardeas y destruidos como lo...</td>\n",
       "      <td>{religion}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>8335</td>\n",
       "      <td>0.957913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user You cannot argue with a retard jer...</td>\n",
       "      <td>{nationality, disability}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>64112</td>\n",
       "      <td>0.994864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I just pound that pussy an pull your hair....</td>\n",
       "      <td>{gender}</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>22034</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you do not live in america nazi faggot but you...</td>\n",
       "      <td>{sexuality}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>18143</td>\n",
       "      <td>0.985650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  India is one nasty, dirty, filthy, germsy, law...   \n",
       "1  solo que seras bombardeas y destruidos como lo...   \n",
       "2  @user @user You cannot argue with a retard jer...   \n",
       "3  Can I just pound that pussy an pull your hair....   \n",
       "4  you do not live in america nazi faggot but you...   \n",
       "\n",
       "            extracted_target platform is_hatespeech     id  cardiff_score  \\\n",
       "0              {nationality}  youtube             1  53513       0.994301   \n",
       "1                 {religion}      gab             1   8335       0.957913   \n",
       "2  {nationality, disability}  twitter             1  64112       0.994864   \n",
       "3                   {gender}   reddit             1  22034       0.977588   \n",
       "4                {sexuality}      gab             1  18143       0.985650   \n",
       "\n",
       "   cardiff_hatespeech  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# GitHub raw content URL for the pickle file\n",
    "github_raw_url = \"https://github.com/Takosaga/master_thesis/raw/main/data/processed/experiement_samples.pkl\" \n",
    "# Download the pickle file\n",
    "response = requests.get(github_raw_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Load the pickle data into a pandas DataFrame\n",
    "    df = pd.read_pickle(BytesIO(response.content))\n",
    "    print(f\"DataFrame loaded successfully with {len(df)} rows\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nPreview of the DataFrame:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, seed, text_column=\"text\"):\n",
    "    \"\"\"Process an entire dataframe with efficient batching\"\"\"\n",
    "    all_texts = df[text_column].tolist()\n",
    "    total_texts = len(all_texts)\n",
    "    \n",
    "    # Get predictions in batch\n",
    "    cardiff_preds = pipe_cardiff(all_texts)\n",
    "    \n",
    "    results = []\n",
    "    for i, text in tqdm(enumerate(all_texts), total=total_texts, desc=\"Processing texts\"):\n",
    "        try:\n",
    "            set_seed(seed)\n",
    "            pred_cardiff = cardiff_preds[i]\n",
    "            \n",
    "            # Calculate explanations for all examples and setting seed\n",
    "            set_seed(seed)\n",
    "            explainer_shap_cardiff = shap.Explainer(predict_cardiff,\n",
    "                                       seed=seed,\n",
    "                                       masker=shap.maskers.Text(tokenizer_cardiff))\n",
    "            shap_exp_cardiff = get_shap_values(text, explainer_shap_cardiff)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"error\": None,\n",
    "                \"cardiff_label\": pred_cardiff[\"label\"],\n",
    "                \"cardiff_score\": pred_cardiff[\"score\"],\n",
    "                \"shap_cardiff\": shap_exp_cardiff,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"error\": f\"Caught an exception: {e}\",\n",
    "                \"cardiff_label\": None,\n",
    "                \"cardiff_score\": None,\n",
    "                \"shap_cardiff\": None,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, name, base_path='/content/drive/MyDrive/'):\n",
    "    \"\"\"\n",
    "    Save a dataframe to CSV, Excel, and pickle formats.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to save\n",
    "    - name: base name for the files (without extension)\n",
    "    - base_path: directory path where files will be saved\n",
    "    \"\"\"\n",
    "    # Save as CSV\n",
    "    df.to_csv(f'{base_path}{name}.csv', index=False)\n",
    "    \n",
    "    # Save as Excel\n",
    "    df.to_excel(f'{base_path}{name}.xlsx', index=False)\n",
    "    \n",
    "    # Save as pickle\n",
    "    df.to_pickle(f'{base_path}{name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64364f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed_0 = process_dataframe(df, 0)\n",
    "save_dataframe(df_seed_0, 'df_shap_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed_42 = process_dataframe(df, 42)\n",
    "save_dataframe(df_seed_42, 'df_shap_42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed_123 = process_dataframe(df, 123)\n",
    "save_dataframe(df_seed_123, 'df_shap_123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed_2025 = process_dataframe(df, 2025)\n",
    "save_dataframe(df_seed_2025, 'df_shap_2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb84b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
