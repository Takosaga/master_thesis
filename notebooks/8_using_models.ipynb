{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6832185",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a99b3a",
   "metadata": {},
   "source": [
    "### Testing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fee2d",
   "metadata": {},
   "source": [
    "Using the two following models:\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-hate-latest\n",
    "\n",
    "https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "from master_thesis.config import PROCESSED_DATA_DIR, load_dataframe_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_and_targeted_hatespeech_df = load_dataframe_from_pickle(\n",
    "    PROCESSED_DATA_DIR / \"annotated_and_targeted_hatespeech.pkl\"\n",
    ")\n",
    "\n",
    "display(annotated_and_targeted_hatespeech_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87078d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_0 = annotated_and_targeted_hatespeech_df['text'][2]\n",
    "test_text_1 = annotated_and_targeted_hatespeech_df['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18373540",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-hate-latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe(test_text_0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88766e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe(test_text_1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2af920",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name, framework=\"pt\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier(test_text_0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier(test_text_1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43846b24",
   "metadata": {},
   "source": [
    "### Using LIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20546d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['not_hate', 'hate']\n",
    "\n",
    "# Model 1: CardiffNLP\n",
    "pipe_cardiff = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-hate-latest\", return_all_scores=True)\n",
    "\n",
    "# Model 2: Facebook Dynabench\n",
    "pipe_fb = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\", return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cardiff(texts):\n",
    "    return np.array([[score['score'] for score in pipe_cardiff(text)[0]] for text in texts])\n",
    "\n",
    "def predict_fb(texts):\n",
    "    return np.array([[score['score'] for score in pipe_fb(text)[0]] for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b269757",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_cardiff = explainer.explain_instance(test_text_0, predict_cardiff, num_features=10)\n",
    "explanation_cardiff.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_cardiff = explainer.explain_instance(test_text_1, predict_cardiff, num_features=10)\n",
    "explanation_cardiff.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_fb = explainer.explain_instance(test_text_0, predict_fb, num_features=10)\n",
    "explanation_fb.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30326798",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_fb = explainer.explain_instance(test_text_1, predict_fb, num_features=10)\n",
    "explanation_fb.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f720a",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea17e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_0 = [test_text_0]\n",
    "text_list_1 = [test_text_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: CardiffNLP\n",
    "pipe_cardiff = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-hate-latest\", return_all_scores=True)\n",
    "\n",
    "# Model 2: Facebook Dynabench\n",
    "pipe_fb = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\", return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_cardiff = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-hate-latest\")\n",
    "tokenizer_fb = AutoTokenizer.from_pretrained(\"facebook/roberta-hate-speech-dynabench-r4-target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cardiff(texts):\n",
    "    return np.array([[label['score'] for label in pipe_cardiff(text)[0]] for text in texts])\n",
    "\n",
    "def predict_fb(texts):\n",
    "    return np.array([[label['score'] for label in pipe_fb(text)[0]] for text in texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936af276",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_cardiff = shap.Explainer(\n",
    "    predict_cardiff,\n",
    "    masker=shap.maskers.Text(tokenizer_cardiff),\n",
    "    output_names=class_names\n",
    ")\n",
    "\n",
    "explainer_fb = shap.Explainer(\n",
    "    predict_fb,\n",
    "    masker=shap.maskers.Text(tokenizer_fb),\n",
    "    output_names=class_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb03a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_cardiff = explainer_cardiff(text_list_0)\n",
    "shap_values_fb = explainer_fb(text_list_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_cardiff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c14b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_fb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_cardiff = explainer_cardiff(text_list_1)\n",
    "shap_values_fb = explainer_fb(text_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ee42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_cardiff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values_fb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a528e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values for a single instance and a specific class\n",
    "shap_values_cardiff = explainer_cardiff(text_list_0)\n",
    "shap_values_fb = explainer_fb(text_list_0)\n",
    "\n",
    "# Select SHAP values for the \"hate\" class (index 1)\n",
    "shap_values_cardiff_hate = shap_values_cardiff[0][:, 1]\n",
    "shap_values_fb_hate = shap_values_fb[0][:, 1]\n",
    "\n",
    "# Generate waterfall plots for the \"hate\" class\n",
    "print(\"Waterfall plot for CardiffNLP model:\")\n",
    "shap.plots.waterfall(shap_values_cardiff_hate)\n",
    "print(\"Waterfall plot for Facebook Dynabench model:\")\n",
    "shap.plots.waterfall(shap_values_fb_hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values for a single instance and a specific class\n",
    "shap_values_cardiff = explainer_cardiff(text_list_1)\n",
    "shap_values_fb = explainer_fb(text_list_1)\n",
    "\n",
    "# Select SHAP values for the \"hate\" class (index 1)\n",
    "shap_values_cardiff_hate = shap_values_cardiff[0][:, 1]\n",
    "shap_values_fb_hate = shap_values_fb[0][:, 1]\n",
    "\n",
    "# Generate waterfall plots for the \"hate\" class\n",
    "print(\"Waterfall plot for CardiffNLP model:\")\n",
    "shap.plots.waterfall(shap_values_cardiff_hate)\n",
    "print(\"Waterfall plot for Facebook Dynabench model:\")\n",
    "shap.plots.waterfall(shap_values_fb_hate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0abb7",
   "metadata": {},
   "source": [
    "### Applying to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898d9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takosaga/miniconda3/envs/master_thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-20 19:59:29.314786: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-20 19:59:29.338640: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-20 19:59:29.338672: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-20 19:59:29.338694: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-20 19:59:29.344105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-20 19:59:29.932788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ff9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        # Optional: for determinism with CuDNN\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3e6097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "\n",
    "class_names = ['not_hate', 'hate']\n",
    "\n",
    "# Pipelines\n",
    "pipe_cardiff = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-hate-latest\")\n",
    "pipe_fb = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n",
    "\n",
    "# Tokenizers\n",
    "tokenizer_cardiff = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-hate-latest\")\n",
    "tokenizer_fb = AutoTokenizer.from_pretrained(\"facebook/roberta-hate-speech-dynabench-r4-target\")\n",
    "\n",
    "# Prediction functions for LIME (no [0] indexing)\n",
    "def predict_cardiff(texts):\n",
    "    # Ensure input is list of strings\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    return np.array([\n",
    "        [res['score'] for res in pipe_cardiff(text, top_k=5)]\n",
    "        for text in texts\n",
    "    ])\n",
    "\n",
    "def predict_fb(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    return np.array([\n",
    "        [res['score'] for res in pipe_fb(text, top_k=5)]\n",
    "        for text in texts\n",
    "    ])\n",
    "\n",
    "# LIME & SHAP explainers\n",
    "explainer_lime = LimeTextExplainer(class_names=class_names)\n",
    "explainer_shap_cardiff = shap.Explainer(predict_cardiff, masker=shap.maskers.Text(tokenizer_cardiff), output_names=class_names)\n",
    "explainer_shap_fb = shap.Explainer(predict_fb, masker=shap.maskers.Text(tokenizer_fb), output_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e201271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'text': [\"nawt yall niggers ignoring me\",\n",
    "                 \"and this is why i end up with nigger trainee doctors who can not speak properly lack basic knowledge of biology it truly scary if the public only knew\",\n",
    "                 \"this is a neutral sentence\"]}\n",
    "annotated_and_targeted_hatespeech_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814c9f7",
   "metadata": {},
   "source": [
    "The following was individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40828a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_cardiff_explanations = []\n",
    "lime_fb_explanations = []\n",
    "shap_cardiff_explanations = []\n",
    "shap_fb_explanations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f82817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- LIME: Cardiff ----\n",
    "for text in annotated_and_targeted_hatespeech_df[\"text\"]:\n",
    "    lime_cardiff = explainer_lime.explain_instance(text, predict_cardiff, num_features=5)\n",
    "    lime_cardiff_keywords = [f\"{word}: {weight:.2f}\" for word, weight in lime_cardiff.as_list()]\n",
    "    lime_cardiff_explanations.append(\", \".join(lime_cardiff_keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff09459",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_and_targeted_hatespeech_df[\"lime_cardiff\"] = lime_cardiff_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2aeb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- LIME: Facebook ----\n",
    "for text in annotated_and_targeted_hatespeech_df[\"text\"]:\n",
    "    lime_fb = explainer_lime.explain_instance(text, predict_fb, num_features=5)\n",
    "    lime_fb_keywords = [f\"{word}: {weight:.2f}\" for word, weight in lime_fb.as_list()]\n",
    "    lime_fb_explanations.append(\", \".join(lime_fb_keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2484c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_and_targeted_hatespeech_df[\"lime_fb\"] = lime_fb_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d1d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:20, 20.15s/it]               \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- SHAP: Cardiff ----\n",
    "for text in annotated_and_targeted_hatespeech_df[\"text\"]:\n",
    "    shap_vals_cardiff = explainer_shap_cardiff([text])\n",
    "    shap_cardiff_words = [\n",
    "        f\"{feature}: {value:.2f}\"\n",
    "        for feature, value in zip(shap_vals_cardiff[0].data, shap_vals_cardiff[0].values[:, 1])\n",
    "        if abs(value) > 0.01\n",
    "    ]\n",
    "    shap_cardiff_explanations.append(\", \".join(shap_cardiff_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09abea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_and_targeted_hatespeech_df[\"shap_cardiff\"] = shap_cardiff_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab07e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:20, 20.41s/it]               \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- SHAP: Facebook ----\n",
    "for text in annotated_and_targeted_hatespeech_df[\"text\"]:\n",
    "    shap_vals_fb = explainer_shap_fb([text])\n",
    "    shap_fb_words = [\n",
    "        f\"{feature}: {value:.2f}\"\n",
    "        for feature, value in zip(shap_vals_fb[0].data, shap_vals_fb[0].values[:, 1])\n",
    "        if abs(value) > 0.01\n",
    "    ]\n",
    "    shap_fb_explanations.append(\", \".join(shap_fb_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa91e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_and_targeted_hatespeech_df[\"shap_fb\"] = shap_fb_explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26cc2f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>lime_fb</th>\n",
       "      <th>shap_cardiff</th>\n",
       "      <th>shap_fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>nawt: -0.09, niggers: 0.08, me: 0.07, yall: 0....</td>\n",
       "      <td>nawt: -0.02, ignoring: -0.02, yall: -0.01, me:...</td>\n",
       "      <td>n: 0.01, nig: 0.04, gers : -0.03, ignoring : 0.02</td>\n",
       "      <td>n: 0.05, aw: -0.02, t : 0.04, y: -0.01, all : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>with: -0.01, nigger: 0.01, trainee: -0.00, i: ...</td>\n",
       "      <td>nigger: -0.02, scary: 0.00, trainee: 0.00, and...</td>\n",
       "      <td></td>\n",
       "      <td>and : -0.03, end : -0.01, n: -0.03, igger : -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a neutral sentence</td>\n",
       "      <td>a: -0.00, is: -0.00, this: -0.00, sentence: -0...</td>\n",
       "      <td>neutral: -0.00, this: -0.00, sentence: 0.00, a...</td>\n",
       "      <td></td>\n",
       "      <td>this : -0.10, is : 0.04, a : 0.04, sentence: -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                      nawt yall niggers ignoring me   \n",
       "1  and this is why i end up with nigger trainee d...   \n",
       "2                         this is a neutral sentence   \n",
       "\n",
       "                                        lime_cardiff  \\\n",
       "0  nawt: -0.09, niggers: 0.08, me: 0.07, yall: 0....   \n",
       "1  with: -0.01, nigger: 0.01, trainee: -0.00, i: ...   \n",
       "2  a: -0.00, is: -0.00, this: -0.00, sentence: -0...   \n",
       "\n",
       "                                             lime_fb  \\\n",
       "0  nawt: -0.02, ignoring: -0.02, yall: -0.01, me:...   \n",
       "1  nigger: -0.02, scary: 0.00, trainee: 0.00, and...   \n",
       "2  neutral: -0.00, this: -0.00, sentence: 0.00, a...   \n",
       "\n",
       "                                        shap_cardiff  \\\n",
       "0  n: 0.01, nig: 0.04, gers : -0.03, ignoring : 0.02   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                             shap_fb  \n",
       "0  n: 0.05, aw: -0.02, t : 0.04, y: -0.01, all : ...  \n",
       "1  and : -0.03, end : -0.01, n: -0.03, igger : -0...  \n",
       "2  this : -0.10, is : 0.04, a : 0.04, sentence: -...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_and_targeted_hatespeech_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e5408",
   "metadata": {},
   "source": [
    "Following is for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5801d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['not_hate', 'hate']\n",
    "explainer_lime = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Simplified LIME explainers\n",
    "def lime_explain(text, predictor, num_features=4):\n",
    "    exp = explainer_lime.explain_instance(text, predictor, num_features=num_features)\n",
    "    return \", \".join([f\"{word}: {weight:.2f}\" for word, weight in exp.as_list()])\n",
    "\n",
    "# Predictor wrappers\n",
    "def predict_cardiff(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    outputs = pipe_cardiff(texts, top_k=2)\n",
    "    return np.array([\n",
    "        [label['score'] for label in sorted(res, key=lambda x: x['label'])]\n",
    "        for res in outputs\n",
    "    ])\n",
    "\n",
    "def predict_fb(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    outputs = pipe_fb(texts, top_k=2)\n",
    "    return np.array([\n",
    "        [label['score'] for label in sorted(res, key=lambda x: x['label'])]\n",
    "        for res in outputs\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ed9692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(text, explainer):\n",
    "    shap_vals = explainer([text])\n",
    "    return \", \".join([\n",
    "        f\"{feature}: {value:.2f}\"\n",
    "        for feature, value in zip(shap_vals[0].data, shap_vals[0].values)\n",
    "        if abs(value) > 0.01\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8da7c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# SHAP\u001b[39;00m\n\u001b[1;32m     11\u001b[0m shap_vals_cardiff \u001b[38;5;241m=\u001b[39m explainer_shap_cardiff([text])\n\u001b[0;32m---> 12\u001b[0m shap_exp_cardiff \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shap_vals_cardiff[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, shap_vals_cardiff[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(value\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m shap_vals_fb \u001b[38;5;241m=\u001b[39m explainer_shap_fb([text])\n\u001b[1;32m     19\u001b[0m shap_exp_fb \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shap_vals_fb[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, shap_vals_fb[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(value\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     23\u001b[0m ])\n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# SHAP\u001b[39;00m\n\u001b[1;32m     11\u001b[0m shap_vals_cardiff \u001b[38;5;241m=\u001b[39m explainer_shap_cardiff([text])\n\u001b[1;32m     12\u001b[0m shap_exp_cardiff \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shap_vals_cardiff[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, shap_vals_cardiff[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m shap_vals_fb \u001b[38;5;241m=\u001b[39m explainer_shap_fb([text])\n\u001b[1;32m     19\u001b[0m shap_exp_fb \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shap_vals_fb[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata, shap_vals_fb[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(value\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     23\u001b[0m ])\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "for text in annotated_and_targeted_hatespeech_df[\"text\"]:\n",
    "    # Get predictions\n",
    "    pred_cardiff = pipe_cardiff(text)[0]\n",
    "    pred_fb = pipe_fb(text)[0]\n",
    "\n",
    "    # LIME\n",
    "    lime_exp_cardiff = lime_explain(text, predict_cardiff)\n",
    "    lime_exp_fb = lime_explain(text, predict_fb)\n",
    "\n",
    "    # SHAP\n",
    "    shap_vals_cardiff = explainer_shap_cardiff([text])\n",
    "    shap_exp_cardiff = \", \".join([\n",
    "        f\"{feature}: {value:.2f}\"\n",
    "        for feature, value in zip(shap_vals_cardiff[0].data, shap_vals_cardiff[0].values)\n",
    "        if abs(value.item()) > 0.01\n",
    "    ])\n",
    "\n",
    "    shap_vals_fb = explainer_shap_fb([text])\n",
    "    shap_exp_fb = \", \".join([\n",
    "        f\"{feature}: {value:.2f}\"\n",
    "        for feature, value in zip(shap_vals_fb[0].data, shap_vals_fb[0].values)\n",
    "        if abs(value.item()) > 0.01\n",
    "    ])\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"text\": text,\n",
    "        \"cardiff_label\": pred_cardiff['label'],\n",
    "        \"cardiff_score\": pred_cardiff['score'],\n",
    "        \"fb_label\": pred_fb['label'],\n",
    "        \"fb_score\": pred_fb['score'],\n",
    "        \"lime_cardiff\": lime_exp_cardiff,\n",
    "        \"lime_fb\": lime_exp_fb,\n",
    "        \"shap_cardiff\": shap_exp_cardiff,\n",
    "        \"shap_fb\": shap_exp_fb\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6dbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# Preview\n",
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
