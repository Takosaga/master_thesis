{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f110a7f",
   "metadata": {},
   "source": [
    "# Setup for single factor experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d9bac",
   "metadata": {},
   "source": [
    "Using only Cardiff only and changing seeds with using LIME and SHAP default values\n",
    "\n",
    "Will only be done on google colab T4 gpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4a77d",
   "metadata": {},
   "source": [
    "* Seed A: 0\n",
    "* Seed B: 42\n",
    "* Seed C: 123\n",
    "* Seed D: 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e12cf1",
   "metadata": {},
   "source": [
    "Looking at 1% of the dataset where cardiff_score is 1.00 a quater is TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c660f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 13:43:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmaster_thesis.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/takosaga/Projects/master_thesis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "from master_thesis.config import PROCESSED_DATA_DIR, load_dataframe_from_pickle, save_dataframe_as_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ba6f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_hatespeech</th>\n",
       "      <th>id</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>shap_cardiff</th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>fb_score</th>\n",
       "      <th>shap_fb</th>\n",
       "      <th>lime_fb</th>\n",
       "      <th>cardiff_hatespeech</th>\n",
       "      <th>fb_hatespeech</th>\n",
       "      <th>lime_cardiff_wordset</th>\n",
       "      <th>lime_fb_wordset</th>\n",
       "      <th>shap_cardiff_wordset</th>\n",
       "      <th>shap_fb_wordset</th>\n",
       "      <th>jaccard_similarity_cardiff</th>\n",
       "      <th>jaccard_similarity_fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>i : 0.002, getting : 0.001, my : 0.001, baby :...</td>\n",
       "      <td>and: 0.04, my: 0.04, white: -0.03, 9: -0.03</td>\n",
       "      <td>0.687105</td>\n",
       "      <td>: 0.014, i : 0.014, dont : -0.008, think : -0....</td>\n",
       "      <td>white: -0.19, touched: -0.12, dont: -0.11, j: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{my, and, 9, white}</td>\n",
       "      <td>{touched, j, dont, white}</td>\n",
       "      <td>{them, has, white}</td>\n",
       "      <td>{them, not, white}</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>calling : 0.013, ourselves : 0.014, feminists ...</td>\n",
       "      <td>trans: 0.00, gender: 0.00, addressed: 0.00, fe...</td>\n",
       "      <td>0.919145</td>\n",
       "      <td>: -0.014, we : -0.014, cannot : -0.029, contin...</td>\n",
       "      <td>and: 0.13, trans: 0.11, lesbian: 0.11, a: -0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{addressed, feminists, trans, gender}</td>\n",
       "      <td>{a, and, lesbian, trans}</td>\n",
       "      <td>{ourselves, calling, bisexual, feminists}</td>\n",
       "      <td>{if, sheet, feminists, reporting}</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>{race}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>n: 0.010, aw: 0.006, t : 0.007, y: 0.003, all ...</td>\n",
       "      <td>niggers: -0.90, nawt: -0.09, me: 0.07, yall: 0.07</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>n: 0.030, aw: -0.062, t : -0.040, y: 0.129, al...</td>\n",
       "      <td>niggers: -0.96, ignoring: -0.02, nawt: -0.02, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{yall, niggers, nawt, me}</td>\n",
       "      <td>{yall, niggers, ignoring, nawt}</td>\n",
       "      <td>{t, gers, all, ignoring}</td>\n",
       "      <td>{t, gers, all, ignoring}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>{race}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997049</td>\n",
       "      <td>: -0.005, &lt;: -0.005, user: -0.005, &gt; : -0.005,...</td>\n",
       "      <td>chong: -0.44, ching: -0.29, chinese: -0.08, pa...</td>\n",
       "      <td>0.779210</td>\n",
       "      <td>: 0.016, &lt;: 0.016, user: 0.016, &gt; : 0.016, i :...</td>\n",
       "      <td>ching: -0.26, this: -0.24, chong: -0.23, confu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{pakistani, ching, chong, chinese}</td>\n",
       "      <td>{confused, ching, this, chong}</td>\n",
       "      <td>{ing, ong, am, inese}</td>\n",
       "      <td>{ing, how, inese, this}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>{race, gender}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990916</td>\n",
       "      <td>bitch : -0.338, in : -0.145, urger : 0.007, ea...</td>\n",
       "      <td>bitches: -0.44, bitch: -0.28, hate: -0.18, eat...</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>this : 0.007, bitch : -0.478, in : -0.004, wha...</td>\n",
       "      <td>bitch: -0.39, bitches: -0.30, holding: -0.05, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{hate, eating, bitches, bitch}</td>\n",
       "      <td>{i, holding, bitches, bitch}</td>\n",
       "      <td>{white, hate, in, bitch}</td>\n",
       "      <td>{white, hate, burger, bitch}</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text extracted_target  \\\n",
       "0  i dont think im getting my baby them white 9 h...           {none}   \n",
       "1  we cannot continue calling ourselves feminists...           {none}   \n",
       "2                      nawt yall niggers ignoring me           {race}   \n",
       "3  <user> i am bit confused coz chinese ppl can n...           {race}   \n",
       "4  this bitch in whataburger eating a burger with...   {race, gender}   \n",
       "\n",
       "  platform is_hatespeech  id  cardiff_score  \\\n",
       "0  twitter             0   1       0.992369   \n",
       "1  twitter             0   2       0.997838   \n",
       "2  twitter             0   3       0.935527   \n",
       "3  twitter             1   4       0.997049   \n",
       "4  twitter             1   5       0.990916   \n",
       "\n",
       "                                        shap_cardiff  \\\n",
       "0  i : 0.002, getting : 0.001, my : 0.001, baby :...   \n",
       "1  calling : 0.013, ourselves : 0.014, feminists ...   \n",
       "2  n: 0.010, aw: 0.006, t : 0.007, y: 0.003, all ...   \n",
       "3  : -0.005, <: -0.005, user: -0.005, > : -0.005,...   \n",
       "4  bitch : -0.338, in : -0.145, urger : 0.007, ea...   \n",
       "\n",
       "                                        lime_cardiff  fb_score  \\\n",
       "0        and: 0.04, my: 0.04, white: -0.03, 9: -0.03  0.687105   \n",
       "1  trans: 0.00, gender: 0.00, addressed: 0.00, fe...  0.919145   \n",
       "2  niggers: -0.90, nawt: -0.09, me: 0.07, yall: 0.07  0.999480   \n",
       "3  chong: -0.44, ching: -0.29, chinese: -0.08, pa...  0.779210   \n",
       "4  bitches: -0.44, bitch: -0.28, hate: -0.18, eat...  0.999297   \n",
       "\n",
       "                                             shap_fb  \\\n",
       "0  : 0.014, i : 0.014, dont : -0.008, think : -0....   \n",
       "1  : -0.014, we : -0.014, cannot : -0.029, contin...   \n",
       "2  n: 0.030, aw: -0.062, t : -0.040, y: 0.129, al...   \n",
       "3  : 0.016, <: 0.016, user: 0.016, > : 0.016, i :...   \n",
       "4  this : 0.007, bitch : -0.478, in : -0.004, wha...   \n",
       "\n",
       "                                             lime_fb  cardiff_hatespeech  \\\n",
       "0  white: -0.19, touched: -0.12, dont: -0.11, j: ...                   0   \n",
       "1    and: 0.13, trans: 0.11, lesbian: 0.11, a: -0.10                   0   \n",
       "2  niggers: -0.96, ignoring: -0.02, nawt: -0.02, ...                   1   \n",
       "3  ching: -0.26, this: -0.24, chong: -0.23, confu...                   1   \n",
       "4  bitch: -0.39, bitches: -0.30, holding: -0.05, ...                   1   \n",
       "\n",
       "   fb_hatespeech                   lime_cardiff_wordset  \\\n",
       "0              1                    {my, and, 9, white}   \n",
       "1              0  {addressed, feminists, trans, gender}   \n",
       "2              1              {yall, niggers, nawt, me}   \n",
       "3              1     {pakistani, ching, chong, chinese}   \n",
       "4              1         {hate, eating, bitches, bitch}   \n",
       "\n",
       "                   lime_fb_wordset                       shap_cardiff_wordset  \\\n",
       "0        {touched, j, dont, white}                         {them, has, white}   \n",
       "1         {a, and, lesbian, trans}  {ourselves, calling, bisexual, feminists}   \n",
       "2  {yall, niggers, ignoring, nawt}                   {t, gers, all, ignoring}   \n",
       "3   {confused, ching, this, chong}                      {ing, ong, am, inese}   \n",
       "4     {i, holding, bitches, bitch}                   {white, hate, in, bitch}   \n",
       "\n",
       "                     shap_fb_wordset  jaccard_similarity_cardiff  \\\n",
       "0                 {them, not, white}                    0.166667   \n",
       "1  {if, sheet, feminists, reporting}                    0.142857   \n",
       "2           {t, gers, all, ignoring}                    0.000000   \n",
       "3            {ing, how, inese, this}                    0.000000   \n",
       "4       {white, hate, burger, bitch}                    0.333333   \n",
       "\n",
       "   jaccard_similarity_fb  \n",
       "0               0.166667  \n",
       "1               0.000000  \n",
       "2               0.142857  \n",
       "3               0.142857  \n",
       "4               0.142857  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = load_dataframe_from_pickle(\n",
    "    PROCESSED_DATA_DIR / \"models_and_XAI_with_jaccard_similarity_applied.pkl\"\n",
    ")\n",
    "\n",
    "working_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e927a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65216, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53baf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_percent = len(working_df)//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eb8316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter = one_percent//4\n",
    "quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6161c0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'extracted_target',\n",
       " 'platform',\n",
       " 'is_hatespeech',\n",
       " 'id',\n",
       " 'cardiff_score',\n",
       " 'shap_cardiff',\n",
       " 'lime_cardiff',\n",
       " 'fb_score',\n",
       " 'shap_fb',\n",
       " 'lime_fb',\n",
       " 'cardiff_hatespeech',\n",
       " 'fb_hatespeech',\n",
       " 'lime_cardiff_wordset',\n",
       " 'lime_fb_wordset',\n",
       " 'shap_cardiff_wordset',\n",
       " 'shap_fb_wordset',\n",
       " 'jaccard_similarity_cardiff',\n",
       " 'jaccard_similarity_fb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33de3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'text', \n",
    "    'extracted_target',\n",
    "    'platform',\n",
    "    'is_hatespeech',\n",
    "    'id',\n",
    "    'cardiff_score',\n",
    "    'cardiff_hatespeech'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c34218",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d7a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_hatespeech</th>\n",
       "      <th>id</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>cardiff_hatespeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>{race}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>{race}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>{race, gender}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text extracted_target  \\\n",
       "0  i dont think im getting my baby them white 9 h...           {none}   \n",
       "1  we cannot continue calling ourselves feminists...           {none}   \n",
       "2                      nawt yall niggers ignoring me           {race}   \n",
       "3  <user> i am bit confused coz chinese ppl can n...           {race}   \n",
       "4  this bitch in whataburger eating a burger with...   {race, gender}   \n",
       "\n",
       "  platform is_hatespeech  id  cardiff_score  cardiff_hatespeech  \n",
       "0  twitter             0   1       0.992369                   0  \n",
       "1  twitter             0   2       0.997838                   0  \n",
       "2  twitter             0   3       0.935527                   1  \n",
       "3  twitter             1   4       0.997049                   1  \n",
       "4  twitter             1   5       0.990916                   1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d236f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53395, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = working_df[\"cardiff_score\"] >= .95\n",
    "working_df_filtered = working_df[mask]\n",
    "working_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c692783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "sample_size = 163\n",
    "ground_truth_col = 'is_hatespeech'\n",
    "prediction_col = 'cardiff_hatespeech'\n",
    "\n",
    "# True Positives (TP): is_hatespeech=1, cardiff_hatespeech=1\n",
    "tp_condition = (working_df_filtered[ground_truth_col] == 1) & (working_df_filtered[prediction_col] == 1)\n",
    "df_tp = working_df_filtered[tp_condition]\n",
    "\n",
    "# True Negatives (TN): is_hatespeech=0, cardiff_hatespeech=0\n",
    "tn_condition = (working_df_filtered[ground_truth_col] == 0) & (working_df_filtered[prediction_col] == 0)\n",
    "df_tn = working_df_filtered[tn_condition]\n",
    "\n",
    "# False Positives (FP): is_hatespeech=0, cardiff_hatespeech=1\n",
    "fp_condition = (working_df_filtered[ground_truth_col] == 0) & (working_df_filtered[prediction_col] == 1)\n",
    "df_fp = working_df_filtered[fp_condition]\n",
    "\n",
    "# False Negatives (FN): is_hatespeech=1, cardiff_hatespeech=0\n",
    "fn_condition = (working_df_filtered[ground_truth_col] == 1) & (working_df_filtered[prediction_col] == 0)\n",
    "df_fn = working_df_filtered[fn_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76cba524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of True Positives (TP): 16415\n",
      "Number of True Negatives (TN): 24929\n",
      "Number of False Positives (FP): 6516\n",
      "Number of False Negatives (FN): 5535\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNumber of True Positives (TP): {len(df_tp)}\")\n",
    "print(f\"Number of True Negatives (TN): {len(df_tn)}\")\n",
    "print(f\"Number of False Positives (FP): {len(df_fp)}\")\n",
    "print(f\"Number of False Negatives (FN): {len(df_fn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ad00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample and add to list\n",
    "def sample_category(df_category, category_name, num_samples):\n",
    "    if len(df_category) >= num_samples:\n",
    "        sampled_df = df_category.sample(n=num_samples, random_state=42) # random_state for reproducibility\n",
    "    else:\n",
    "        print(f\"Warning: Category '{category_name}' has only {len(df_category)} samples, which is less than {num_samples}. Taking all available samples.\")\n",
    "        sampled_df = df_category.copy() # Take all if less than desired\n",
    "    print(f\"Sampled {len(sampled_df)} from {category_name}\")\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52464ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 163 from True Positives\n",
      "Sampled 163 from True Negatives\n",
      "Sampled 163 from False Positives\n",
      "Sampled 163 from False Negatives\n"
     ]
    }
   ],
   "source": [
    "sampled_dfs = []\n",
    "\n",
    "sampled_tp = sample_category(df_tp, 'True Positives', quarter)\n",
    "sampled_tn = sample_category(df_tn, 'True Negatives', quarter)\n",
    "sampled_fp = sample_category(df_fp, 'False Positives', quarter)\n",
    "sampled_fn = sample_category(df_fn, 'False Negatives', quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a0018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sampled_df = pd.concat([sampled_tp, sampled_tn, sampled_fp, sampled_fn], ignore_index=True)\n",
    "final_sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77384ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_hatespeech</th>\n",
       "      <th>id</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>cardiff_hatespeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India is one nasty, dirty, filthy, germsy, law...</td>\n",
       "      <td>{nationality}</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "      <td>53513</td>\n",
       "      <td>0.994301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solo que seras bombardeas y destruidos como lo...</td>\n",
       "      <td>{religion}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>8335</td>\n",
       "      <td>0.957913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user You cannot argue with a retard jer...</td>\n",
       "      <td>{disability, nationality}</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>64112</td>\n",
       "      <td>0.994864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I just pound that pussy an pull your hair....</td>\n",
       "      <td>{gender}</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>22034</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you do not live in america nazi faggot but you...</td>\n",
       "      <td>{sexuality}</td>\n",
       "      <td>gab</td>\n",
       "      <td>1</td>\n",
       "      <td>18143</td>\n",
       "      <td>0.985650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  India is one nasty, dirty, filthy, germsy, law...   \n",
       "1  solo que seras bombardeas y destruidos como lo...   \n",
       "2  @user @user You cannot argue with a retard jer...   \n",
       "3  Can I just pound that pussy an pull your hair....   \n",
       "4  you do not live in america nazi faggot but you...   \n",
       "\n",
       "            extracted_target platform is_hatespeech     id  cardiff_score  \\\n",
       "0              {nationality}  youtube             1  53513       0.994301   \n",
       "1                 {religion}      gab             1   8335       0.957913   \n",
       "2  {disability, nationality}  twitter             1  64112       0.994864   \n",
       "3                   {gender}   reddit             1  22034       0.977588   \n",
       "4                {sexuality}      gab             1  18143       0.985650   \n",
       "\n",
       "   cardiff_hatespeech  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df91210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to /home/takosaga/Projects/master_thesis/data/processed/experiement_samples.pkl\n"
     ]
    }
   ],
   "source": [
    "save_dataframe_as_pickle(final_sampled_df, PROCESSED_DATA_DIR.as_posix() + '/experiement_samples.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33788a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sampled_df.to_csv(PROCESSED_DATA_DIR.as_posix() + '/experiement_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a65a6",
   "metadata": {},
   "source": [
    "### Setup for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install lime shap hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9e277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c62e5f5a6b4da1922538117ec938f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>error</th>\n",
       "      <th>cardiff_label</th>\n",
       "      <th>cardiff_score</th>\n",
       "      <th>lime_cardiff</th>\n",
       "      <th>shap_cardiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>None</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.935527</td>\n",
       "      <td>niggers: -0.907, nawt: -0.102, me: 0.074, yall...</td>\n",
       "      <td>n: 0.010, aw: 0.006, t : 0.007, y: 0.003, all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>None</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>nigger: -0.981, with: -0.007, i: 0.004, doctor...</td>\n",
       "      <td>and : 0.003, this : 0.001, n: -0.007, igger : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a neutral sentence</td>\n",
       "      <td>None</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.999157</td>\n",
       "      <td>a: 0.001, is: 0.001, this: 0.001, sentence: 0....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text error cardiff_label  \\\n",
       "0                      nawt yall niggers ignoring me  None          HATE   \n",
       "1  and this is why i end up with nigger trainee d...  None          HATE   \n",
       "2                         this is a neutral sentence  None      NOT-HATE   \n",
       "\n",
       "   cardiff_score                                       lime_cardiff  \\\n",
       "0       0.935527  niggers: -0.907, nawt: -0.102, me: 0.074, yall...   \n",
       "1       0.993975  nigger: -0.981, with: -0.007, i: 0.004, doctor...   \n",
       "2       0.999157  a: 0.001, is: 0.001, this: 0.001, sentence: 0....   \n",
       "\n",
       "                                        shap_cardiff  \n",
       "0  n: 0.010, aw: 0.006, t : 0.007, y: 0.003, all ...  \n",
       "1  and : 0.003, this : 0.001, n: -0.007, igger : ...  \n",
       "2                                                     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity test\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import random\n",
    "import torch\n",
    "from typing import List, Union\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        # Optional: for determinism with CuDNN\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Constants\n",
    "CLASS_NAMES = ['NOT-HATE', 'HATE']\n",
    "BATCH_SIZE = 512  # Adjust based on your GPU memory\n",
    "\n",
    "# Load models and tokenizers once\n",
    "pipe_cardiff = pipeline(\"text-classification\", \n",
    "                       model=\"cardiffnlp/twitter-roberta-base-hate-latest\", \n",
    "                       device=0 if torch.cuda.is_available() else -1,\n",
    "                       batch_size=BATCH_SIZE)\n",
    "\n",
    "tokenizer_cardiff = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-hate-latest\")\n",
    "\n",
    "# Create dataset class for more efficient processing\n",
    "class HateSpeechDataset:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "\n",
    "# Unified prediction function for both models\n",
    "def batch_predict(texts: Union[List[str], np.ndarray], pipeline_fn):\n",
    "    \"\"\"Run predictions in batches for efficiency\"\"\"\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "        \n",
    "    dataset = HateSpeechDataset(texts)\n",
    "    \n",
    "    # Process in batches\n",
    "    all_outputs = []\n",
    "    for i in range(0, len(dataset), BATCH_SIZE):\n",
    "        batch_texts = [dataset[j] for j in range(i, min(i + BATCH_SIZE, len(dataset)))]\n",
    "        outputs = pipeline_fn(batch_texts, top_k=2)\n",
    "        all_outputs.extend(outputs)\n",
    "    \n",
    "    # Convert to numpy array with consistent order\n",
    "    return np.array([\n",
    "        [label['score'] for label in sorted(res, key=lambda x: x['label'])]\n",
    "        for res in all_outputs\n",
    "    ])\n",
    "\n",
    "\n",
    "# Model-specific prediction functions\n",
    "def predict_cardiff(texts):\n",
    "    return batch_predict(texts, pipe_cardiff)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize explainers\n",
    "explainer_lime = LimeTextExplainer(class_names=CLASS_NAMES)\n",
    "explainer_shap_cardiff = shap.Explainer(predict_cardiff, \n",
    "                                       masker=shap.maskers.Text(tokenizer_cardiff))\n",
    "\n",
    "# Helper function for LIME explanations\n",
    "def lime_explain(text, predictor, num_features=4):\n",
    "    exp = explainer_lime.explain_instance(text, \n",
    "                                          predictor)\n",
    "    return \", \".join([f\"{word}: {weight:.3f}\" for word, weight in exp.as_list()])\n",
    "\n",
    "\n",
    "# Helper function for SHAP explanations\n",
    "def get_shap_values(text, explainer, class_idx=1):\n",
    "    shap_vals = explainer([text])\n",
    "    return \", \".join([\n",
    "        f\"{feature}: {value:.3f}\"\n",
    "        for feature, value in zip(shap_vals[0].data, shap_vals[0].values[:, class_idx])\n",
    "        if abs(value) > 0.001\n",
    "    ])\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"nawt yall niggers ignoring me\",\n",
    "        \"and this is why i end up with nigger trainee doctors who can not speak properly lack basic knowledge of biology it truly scary if the public only knew\",\n",
    "        \"this is a neutral sentence\"\n",
    "    ]\n",
    "}\n",
    "annotated_and_targeted_hatespeech_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Process all texts in one batch for efficiency\n",
    "all_texts = annotated_and_targeted_hatespeech_df[\"text\"].tolist()\n",
    "\n",
    "# Get predictions in batch\n",
    "cardiff_preds = pipe_cardiff(all_texts) \n",
    "\n",
    "# Process results\n",
    "results = []\n",
    "for i, text in enumerate(all_texts):\n",
    "    try:\n",
    "        # Get predictions from the batch results\n",
    "        pred_cardiff = cardiff_preds[i]\n",
    "\n",
    "        # LIME explanations\n",
    "        lime_exp_cardiff = lime_explain(text, predict_cardiff)\n",
    "\n",
    "        # SHAP explanations\n",
    "        shap_exp_cardiff = get_shap_values(text, explainer_shap_cardiff)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"error\": None,\n",
    "            \"cardiff_label\": pred_cardiff[\"label\"],\n",
    "            \"cardiff_score\": pred_cardiff[\"score\"],\n",
    "            \"lime_cardiff\": lime_exp_cardiff,\n",
    "            \"shap_cardiff\": shap_exp_cardiff\n",
    "        })\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"error\": f\"Caught an exception: {e}\",\n",
    "            \"cardiff_label\": None,\n",
    "            \"cardiff_score\": None,\n",
    "            \"lime_cardiff\": None,\n",
    "            \"shap_cardiff\": None\n",
    "        })\n",
    "\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41244756",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Saving to drive\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save to your Google Drive\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Saving to drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Save to your Google Drive\n",
    "final_df.to_csv('/content/drive/MyDrive/hate_speech_analysis_results.csv', index=False)\n",
    "final_df.to_excel('/content/drive/MyDrive/hate_speech_analysis_results.xlsx', index=False)\n",
    "final_df.to_pickle('/content/drive/MyDrive/hate_speech_analysis_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbef335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully with 65217 rows\n",
      "\n",
      "Preview of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_new</th>\n",
       "      <th>text</th>\n",
       "      <th>extracted_target</th>\n",
       "      <th>label_hatespeech_binary_offensive_not_included</th>\n",
       "      <th>label_hatespeech_binary_offensive_included</th>\n",
       "      <th>label_normal_offensive_hatespeech</th>\n",
       "      <th>platform</th>\n",
       "      <th>original_dataset_title</th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_label</th>\n",
       "      <th>original_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179055004553900032</td>\n",
       "      <td>normal</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>{none}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179063826874032128</td>\n",
       "      <td>normal</td>\n",
       "      <td>[None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>{race}</td>\n",
       "      <td>not_hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1178793830532956161</td>\n",
       "      <td>normal</td>\n",
       "      <td>[African]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>{race}</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech/offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179088797964763136</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[Asian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>{race, gender}</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech/offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>twitter</td>\n",
       "      <td>HateXplain</td>\n",
       "      <td>1179085312976445440</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[Caucasian, Women]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_new                                               text extracted_target  \\\n",
       "0       1  i dont think im getting my baby them white 9 h...           {none}   \n",
       "1       2  we cannot continue calling ourselves feminists...           {none}   \n",
       "2       3                      nawt yall niggers ignoring me           {race}   \n",
       "3       4  <user> i am bit confused coz chinese ppl can n...           {race}   \n",
       "4       5  this bitch in whataburger eating a burger with...   {race, gender}   \n",
       "\n",
       "  label_hatespeech_binary_offensive_not_included  \\\n",
       "0                                 not_hatespeech   \n",
       "1                                 not_hatespeech   \n",
       "2                                 not_hatespeech   \n",
       "3                                     hatespeech   \n",
       "4                                     hatespeech   \n",
       "\n",
       "  label_hatespeech_binary_offensive_included  \\\n",
       "0                                     normal   \n",
       "1                                     normal   \n",
       "2                                     normal   \n",
       "3                       hatespeech/offensive   \n",
       "4                       hatespeech/offensive   \n",
       "\n",
       "  label_normal_offensive_hatespeech platform original_dataset_title  \\\n",
       "0                            normal  twitter             HateXplain   \n",
       "1                            normal  twitter             HateXplain   \n",
       "2                            normal  twitter             HateXplain   \n",
       "3                        hatespeech  twitter             HateXplain   \n",
       "4                        hatespeech  twitter             HateXplain   \n",
       "\n",
       "           original_id original_label     original_target  \n",
       "0  1179055004553900032         normal              [None]  \n",
       "1  1179063826874032128         normal              [None]  \n",
       "2  1178793830532956161         normal           [African]  \n",
       "3  1179088797964763136     hatespeech             [Asian]  \n",
       "4  1179085312976445440     hatespeech  [Caucasian, Women]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 15:40:16,284 - INFO     - Executing shutdown due to inactivity...\n",
      "2025-05-04 15:40:16,288 - INFO     - Executing shutdown...\n",
      "2025-05-04 15:40:16,289 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n",
      "/home/takosaga/miniconda3/envs/master_thesis/lib/python3.10/site-packages/dtale/app.py:445: FutureWarning:\n",
      "\n",
      "`torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# GitHub raw content URL for the pickle file\n",
    "github_raw_url = \"https://github.com/Takosaga/master_thesis/raw/main/data/processed/annotated_and_targeted_hatespeech.pkl\" # Updated URL\n",
    "# Download the pickle file\n",
    "response = requests.get(github_raw_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Load the pickle data into a pandas DataFrame\n",
    "    df = pd.read_pickle(BytesIO(response.content))\n",
    "    print(f\"DataFrame loaded successfully with {len(df)} rows\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nPreview of the DataFrame:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d46bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[:\u001b[38;5;241m100\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c672b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, text_column=\"text\"):\n",
    "    \"\"\"Process an entire dataframe with efficient batching\"\"\"\n",
    "    all_texts = df[text_column].tolist()\n",
    "    total_texts = len(all_texts)\n",
    "    \n",
    "    # Get predictions in batch\n",
    "    cardiff_preds = pipe_cardiff(all_texts)\n",
    "    \n",
    "    results = []\n",
    "    for i, text in tqdm(enumerate(all_texts), total=total_texts, desc=\"Processing texts\"):\n",
    "        try:\n",
    "\n",
    "            pred_cardiff = cardiff_preds[i]\n",
    "            \n",
    "            # Calculate explanations for all examples\n",
    "            lime_exp_cardiff = lime_explain(text, predict_cardiff)\n",
    "            shap_exp_cardiff = get_shap_values(text, explainer_shap_cardiff)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"error\": None,\n",
    "                \"cardiff_label\": pred_cardiff[\"label\"],\n",
    "                \"cardiff_score\": pred_cardiff[\"score\"],\n",
    "                \"lime_cardiff\": lime_exp_cardiff,\n",
    "                \"shap_cardiff\": shap_exp_cardiff,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"error\": f\"Caught an exception: {e}\",\n",
    "                \"cardiff_label\": None,\n",
    "                \"cardiff_score\": None,\n",
    "                \"lime_cardiff\": None,\n",
    "                \"shap_cardiff\": None,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "section = len(df)//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, name, base_path='/content/drive/MyDrive/'):\n",
    "    \"\"\"\n",
    "    Save a dataframe to CSV, Excel, and pickle formats.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to save\n",
    "    - name: base name for the files (without extension)\n",
    "    - base_path: directory path where files will be saved\n",
    "    \"\"\"\n",
    "    # Save as CSV\n",
    "    df.to_csv(f'{base_path}{name}.csv', index=False)\n",
    "    \n",
    "    # Save as Excel\n",
    "    df.to_excel(f'{base_path}{name}.xlsx', index=False)\n",
    "    \n",
    "    # Save as pickle\n",
    "    df.to_pickle(f'{base_path}{name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "df_1 = process_dataframe(df[:section])\n",
    "save_dataframe(df_1, 'df_1_seed42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "df_1 = process_dataframe(df[:section])\n",
    "save_dataframe(df_1, 'df_1_seed0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
